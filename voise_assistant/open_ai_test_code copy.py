# https://www.youtube.com/watch?v=Ew7fOQpkKBw
import os
from gpt4all import GPT4All

model_path = r"C:\Users\yehor\AppData\Local\nomic.ai\GPT4All\Llama-3.2-1B-Instruct-Q4_0.gguf"

# # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏
if not os.path.exists(model_path):
    raise FileNotFoundError(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {model_path}")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
local_model = GPT4All(model_path, allow_download=False)

# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
# response = model.generate("Hello! How are you?")
# print("ü§ñ AI:", response)

class LocalModel:
    def __init__(self):
        self.model = local_model
    
    def generate_response(self, message):
        return self.model.generate(message)

# Replace OpenAI's model with LocalModel
model = LocalModel()
